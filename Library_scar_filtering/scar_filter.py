#!/usr/bin/env python

# scar_filter is a pipeline to filter out scars generated by sequencing errors.
# Author: B. Spanjaard
# Last update: 14/3/2017

# Filtering is done on barcode, UMI and scar sequence. We consecutively consider
# scar sequences that have the same barcode and UMI, UMIs that have the same
# barcode and scar sequence, and barcodes that have the same UMI and scar
# sequence. In each step we take the instance (scar sequence, UMI and barcode
# respectively) with the highest amount of reads.
# The rationale behind this is that it is exceedingly improbable to have two
# scar sequences in the same cell with the same UMI, that we do not particularly
# care how many UMIs of a given scar sequence in a given cell we see, and that
# (again) it is very unlikely to have a scar sequence with the same UMI appear
# in two different cells.

# Dependencies
from optparse import OptionParser
#import numpy as np
import pandas as pd
import distance

# Get input parameters
# Input filename, output filename.
parser = OptionParser()
input_help = """
Scar reads file - format:
Count | CIGAR | Barcode | UMI | Location | Sequence
"""
parser.add_option("-i", dest="input_file", help=input_help)
parser.add_option("-o", dest="output_file", help="Output filename")
(options, args) = parser.parse_args()

# filter_results_out_file = "../scar_filter/filter_results.csv"
out_file = options.output_file # "../scar_filter/out.csv"
in_file = options.input_file # "../scar_filter/scar_10X_reads_over1.txt"

# Read input dataframe
input_reads = pd.read_csv(
    in_file, sep="\s+", header=None,
    names=['Reads', 'CIGAR', 'Barcode', 'UMI', 'Location', 'Sequence'])

# Keep dominant sequence for each bc + UMI combination
bcUMI_frame = pd.DataFrame(input_reads['Barcode'] + input_reads['UMI'])
bcUMI_frame = bcUMI_frame.rename(columns={0: 'bcUMI'})
bcUMI_frame = pd.concat([input_reads, bcUMI_frame], axis=1)

bcUMI_max = bcUMI_frame.groupby('bcUMI')[['Reads']].max()
bcUMI_max.index.name = 'bcUMI'
bcUMI_max.reset_index(inplace=True)
bcUMI_select = pd.merge(bcUMI_frame, bcUMI_max,
                        left_on=['bcUMI', 'Reads'],
                        right_on=['bcUMI', 'Reads'],
                        how='inner')

# Keep dominant UMI for each barcode + sequence combination
# This heaps sequencing errors and valid UMIs with less reads
# and will therefore underestimate the number of transcripts
# detected. Do we need to improve this?
bcSeq_frame = pd.DataFrame(bcUMI_select['Barcode'] + bcUMI_select['Sequence'])
bcSeq_frame = bcSeq_frame.rename(columns={0: 'bcSeq'})
bcSeq_frame = pd.concat([bcUMI_select, bcSeq_frame], axis=1)

bcSeq_max = bcSeq_frame.groupby('bcSeq')[['Reads']].max()
bcSeq_max.index.name = 'bcSeq'
bcSeq_max.reset_index(inplace=True)
bcSeq_select = pd.merge(bcSeq_frame, bcSeq_max,
                        left_on=['bcSeq', 'Reads'],
                        right_on=['bcSeq', 'Reads'],
                        how='inner')

# Keep dominant barcode for each UMI + Sequence combination
UMISeq_frame = pd.DataFrame(bcSeq_select['UMI'] + bcSeq_select['Sequence'])
UMISeq_frame = UMISeq_frame.rename(columns={0: 'UMISeq'})
UMISeq_frame = pd.concat([bcSeq_select, UMISeq_frame], axis=1)

UMISeq_max = UMISeq_frame.groupby('UMISeq')[['Reads']].max()
UMISeq_max.index.name = 'UMISeq'
UMISeq_max.reset_index(inplace=True)
UMISeq_select = pd.merge(UMISeq_frame, UMISeq_max,
                        left_on=['UMISeq', 'Reads'],
                        right_on=['UMISeq', 'Reads'],
                        how='inner')

UMISeq_select.to_csv(out_file,
                   columns=['Reads', 'CIGAR', 'Barcode', 'UMI', 'Location', 'Sequence'],
                     sep='\t', index=False)
